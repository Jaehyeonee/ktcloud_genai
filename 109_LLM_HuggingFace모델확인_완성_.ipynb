{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmVO_XULPo7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyBc3Lm3PrXK",
        "outputId": "ec7383e4-8493-4e87-d0e9-bdf8b2bc7438"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face ëª¨ë¸ í™•ì¸í•˜ê¸°**"
      ],
      "metadata": {
        "id": "xAPO58qbDYi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAmo5uhXQ46c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ğŸ’¡ **NOTE**\n",
        "    - ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”."
      ],
      "metadata": {
        "id": "KHIcfXn8RArA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "K-OX9xcYMp_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.Hugging Face ì‚¬ìš©**"
      ],
      "metadata": {
        "id": "QD5DBVW269sN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Hugging Face**\n",
        "    - Hugging FaceëŠ” AI ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ê³µìœ Â·í™œìš©í•  ìˆ˜ ìˆëŠ” ëŒ€í‘œì ì¸ ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼, ì»¤ë®¤ë‹ˆí‹°\n",
        "        - **ëª¨ë¸ í—ˆë¸Œ(Model Hub)** : ìˆ˜ë§Œ ê°œì˜ ê³µê°œëœ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ëˆ„êµ¬ë‚˜ ë‹¤ìš´ë¡œë“œÂ·í™œìš© ê°€ëŠ¥\n",
        "        - **ë°ì´í„°ì…‹ í—ˆë¸Œ(Datasets)** : ë‹¤ì–‘í•œ í‘œì¤€/ë¹„í‘œì¤€ ë°ì´í„°ì…‹ì„ ê°„í¸í•˜ê²Œ ë¶ˆëŸ¬ì™€ ì‹¤í—˜ ê°€ëŠ¥\n",
        "        - **Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬** : BERT, GPT, T5, LLaMA ë“± ìµœì‹  NLPÂ·ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì„ ì†ì‰½ê²Œ ì‚¬ìš© ê°€ëŠ¥\n",
        "        - **PEFT/Accelerate ë“± ë„êµ¬** : íŒŒì¸íŠœë‹Â·ë¶„ì‚° í•™ìŠµÂ·ìµœì í™” ì§€ì›\n",
        "        - **ì»¤ë®¤ë‹ˆí‹°**: ì—°êµ¬ìÂ·ê°œë°œìê°€ ëª¨ë¸ê³¼ ì½”ë“œë¥¼ ê³µìœ í•˜ê³  í˜‘ì—…í•  ìˆ˜ ìˆëŠ” ìƒíƒœê³„\n",
        "\n",
        "- **transformers**\n",
        "    - transformers library https://huggingface.co/docs/transformers/index\n",
        "    - Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ì‚¬ì „ í›ˆë ¨ëœ AI ëª¨ë¸ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "    - ë³µì¡í•œ AI ëª¨ë¸ì„ ê°„ë‹¨í•œ ì½”ë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬\n",
        "\n",
        "- **pipeline**\n",
        "    - https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
        "    - pipelineì€ ìì—°ì–´ ì²˜ë¦¬(NLP)Â·ë¹„ì „Â·ì˜¤ë””ì˜¤ ë“± ë‹¤ì–‘í•œ AI íƒœìŠ¤í¬ë¥¼ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ êµ¬ì„±ëœ ì¶”ë¡ (ì‹¤í–‰) ë„êµ¬\n",
        "    - íƒœìŠ¤í¬ ì´ë¦„(ì˜ˆ: \"sentiment-analysis\", \"translation\")ì„ ì…ë ¥í•˜ë©´,ìë™ìœ¼ë¡œ ì í•©í•œ ëª¨ë¸ + í† í¬ë‚˜ì´ì € + ì „/í›„ì²˜ë¦¬ ë¡œì§ì„ ë¶ˆëŸ¬ì™€,ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€/ì˜¤ë””ì˜¤ë¥¼ ë°”ë¡œ ë„£ì–´ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆê²Œ í•¨\n",
        "\n",
        "    - **pipeline(sentiment-analysis)**\n",
        "        - Hugging Face Pipelines Documentation :  \n",
        "        - í…ìŠ¤íŠ¸ì˜ ê°ì •(ê¸ì •/ë¶€ì •) ë¶„ì„ì— íŠ¹í™”ëœ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì˜ ì‘ì—…(task) ì´ë¦„\n",
        "        - ê°ì • ë¶„ì„ì— íŠ¹í™”ëœ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì‘ì—…(task) ì´ë¦„\n",
        "        - (AIëª¨ë¸ X) ë‚´ë¶€ì ìœ¼ë¡œ BERT, RoBERTa, DistilBERT ë“±ì˜ ì‹¤ì œ ì‹ ê²½ë§ ëª¨ë¸ì´ ë™ì‘\n"
      ],
      "metadata": {
        "id": "olZXCZdcWh_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì˜ˆì œ 1: ëª¨ë¸ ì •ë³´ í™•ì¸í•˜ê¸°**"
      ],
      "metadata": {
        "id": "jNIZzwy-Af3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import model_info\n",
        "\n",
        "# ì˜ˆ: BERT base uncased ëª¨ë¸ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "# info = model_info(\"bert-base-uncased\")\n",
        "info = model_info(\"google-bert/bert-base-uncased\")\n",
        "# info = model_info(\"Qwen/Qwen3-Omni-30B-A3B-Instruct\")\n",
        "\n",
        "# ì „ì²´ ë©”íƒ€ë°ì´í„° ë³´ê¸°\n",
        "print(info.cardData)\n",
        "\n",
        "# íŠ¹ì • í•­ëª© ì¶”ì¶œ (ìˆì„ ê²½ìš°ë§Œ)\n",
        "if \"model_size\" in info.cardData:\n",
        "    print(\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜:\", info.cardData[\"model_size\"])\n",
        "if \"datasets\" in info.cardData:\n",
        "    print(\"í•™ìŠµ ë°ì´í„°ì…‹:\", info.cardData[\"datasets\"])\n"
      ],
      "metadata": {
        "id": "lg8uzS0R8qJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b0addf-4a87-4639-8cd7-3ba6b2fe33e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets:\n",
            "- bookcorpus\n",
            "- wikipedia\n",
            "language: en\n",
            "license: apache-2.0\n",
            "tags:\n",
            "- exbert\n",
            "í•™ìŠµ ë°ì´í„°ì…‹: ['bookcorpus', 'wikipedia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info.author"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ssjyX-5RQPUV",
        "outputId": "10d9501a-8a24-4a8b-a15f-174e5d579ecd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'google-bert'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer, BertConfig\n",
        "import torch\n",
        "\n",
        "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "model_name = \"google-bert/bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "\n",
        "# ëª¨ë¸ êµ¬ì„± ì •ë³´ ì¶œë ¥\n",
        "print(\"=== BERT Base Uncased ëª¨ë¸ ì •ë³´ ===\")\n",
        "print(f\"ëª¨ë¸ ì´ë¦„: {model_name}\")\n",
        "print(f\"ì–´íœ˜ ì‚¬ì „ í¬ê¸°: {config.vocab_size}\")\n",
        "print(f\"íˆë“  ë ˆì´ì–´ ìˆ˜: {config.num_hidden_layers}\")\n",
        "print(f\"íˆë“  ì‚¬ì´ì¦ˆ: {config.hidden_size}\")\n",
        "print(f\"ì–´í…ì…˜ í—¤ë“œ ìˆ˜: {config.num_attention_heads}\")\n",
        "print(f\"ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {config.max_position_embeddings}\")\n",
        "\n",
        "# íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,} ({total_params/1e6:.1f}M)\")"
      ],
      "metadata": {
        "id": "AiXxzDp3AVdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "78b3fbd991ed44d8b53d94a50faa1d15",
            "aac6715b9af6401babaef661ef729210",
            "dee74345fe9345d3864861760815ba4a",
            "a8a5a90c3c894f87a6accc236413509c",
            "47cc1d6940094cdb97d5d26542e9700c",
            "1f40d36bf2604d219abe7075d6616032",
            "24157fd011c64dbaa3a6c84964bea532",
            "ac485663fe86466a91d2e8a806b0e541",
            "16bcecf727c7439fb18c5d258561f2f0",
            "41c34e87e3f2418e89ab240f1db9b756",
            "88aaf11ac4344d4fad858bce6308ccdf",
            "7a1765ca6c1c41dfafd64c98e0c3f4df",
            "92f0c87c0d8947eaab93db02bcbac93b",
            "69f519caaae34fb5b1c4f1e6a868fb45",
            "3238c2bb9197496eba8773869892bee1",
            "5143b7fe23124d92a3207ffac09e7f02",
            "702c3725fd9c47b78a56899bda35a7b9",
            "93005980ef9d43b6a64d1ef04510d02c",
            "033878ecd49f4bff89f9d0b3a50e850a",
            "d205e07a241f4c86b0cbf5c470d53886",
            "db724a2e9d93441dbb5d46a449896e13",
            "4b83782abb564b44a5b411ccf968d007",
            "35a53a085400420e8766516dff32464a",
            "ce9543c8f8194ad7ae3d3b4fa01de03f",
            "e8aa4b41cfb54c4ea64e10bdeca67dff",
            "5c04a61077a044fa8398288ce01cfd58",
            "59e4a77952d34c21ad6bcc743c2323a4",
            "6371e3f1758f400da290fc8e736eaa9d",
            "a30c4830accb4699a73ac2f5ddcfb458",
            "bf0bd9e29a1e4694807c2dab6ad979fa",
            "c00b2b5934a346cab806f0e919de8964",
            "0163a6d106cf4af381cba38c42d74c0d",
            "4ecae741dfd14a918fab068d975cf2b9",
            "8df061aa349d4bb2b7cc4b1d9e66f4e7",
            "a962bc3400154029bfffc3ef803310f8",
            "3bf11ab44f57485988d53386f0f56fff",
            "8bbaeee2cd9b43b5a449985231066fe1",
            "739a7a4e94dc464fb7e26c63be062abc",
            "24d9ef30b01c4b958ea3052b8fbc164a",
            "fa561740fee74bb391eb984c73881268",
            "4820af5fa5b64a74b5aabe7e6b6b7b0a",
            "cd9259d980d14049a42311e46b9f3b72",
            "5b84b74fa0674564a0b98eadf2345f85",
            "354894b3e0e14514a4ba581d1a45d44e",
            "6f6f68528ade45dfb78def142039d9b0",
            "dce46cf8c77240b4914c3fc9a9bb768c",
            "7310204367d54ed1afaed5738de0b7a9",
            "e3a1352d4d76428ebb9da2d0f844b720",
            "740e436c0e824266b2a5c856ee50061d",
            "6623fabfac8740358d607102345b875b",
            "1f52124db0d84e0e8c11ecf503267807",
            "9229577ff2da4a5cb66a04ae18be5d08",
            "736bbb7d878840468267d9ea318cf479",
            "02044ad4842f495c90f50fd4145c31f7",
            "f92c767112104818b0095abfc3518deb"
          ]
        },
        "outputId": "e5e35905-08a9-4f08-b6d8-6c08781911e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78b3fbd991ed44d8b53d94a50faa1d15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a1765ca6c1c41dfafd64c98e0c3f4df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35a53a085400420e8766516dff32464a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8df061aa349d4bb2b7cc4b1d9e66f4e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f6f68528ade45dfb78def142039d9b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BERT Base Uncased ëª¨ë¸ ì •ë³´ ===\n",
            "ëª¨ë¸ ì´ë¦„: google-bert/bert-base-uncased\n",
            "ì–´íœ˜ ì‚¬ì „ í¬ê¸°: 30522\n",
            "íˆë“  ë ˆì´ì–´ ìˆ˜: 12\n",
            "íˆë“  ì‚¬ì´ì¦ˆ: 768\n",
            "ì–´í…ì…˜ í—¤ë“œ ìˆ˜: 12\n",
            "ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: 512\n",
            "ì´ íŒŒë¼ë¯¸í„° ìˆ˜: 109,482,240 (109.5M)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì˜ˆì œ 2: ëª¨ë¸ ì‚¬ìš©í•´ë³´ê¸°**"
      ],
      "metadata": {
        "id": "EQnXm72-ApDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì‹œ í…ìŠ¤íŠ¸ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# ëª¨ë¸ ì¶”ë¡ \n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# ê²°ê³¼ ë¶„ì„\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(f\"ì…ë ¥ í…ìŠ¤íŠ¸: {text}\")\n",
        "print(f\"í† í°í™”ëœ ì…ë ¥: {tokenizer.tokenize(text)}\")\n",
        "print(f\"ì¶œë ¥ í…ì„œ í¬ê¸°: {last_hidden_states.shape}\")\n",
        "print(f\"ê° í† í°ì˜ ì„ë² ë”© ì°¨ì›: {last_hidden_states.shape[-1]}\")"
      ],
      "metadata": {
        "id": "TDExX_RNApi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d45551-65e6-42ba-d0e9-f18459bad835"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì…ë ¥ í…ìŠ¤íŠ¸: The quick brown fox jumps over the lazy dog.\n",
            "í† í°í™”ëœ ì…ë ¥: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "ì¶œë ¥ í…ì„œ í¬ê¸°: torch.Size([1, 12, 768])\n",
            "ê° í† í°ì˜ ì„ë² ë”© ì°¨ì›: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Masked Language Modeling(MLM)ì†Œê°œ**\n",
        "ë§ˆìŠ¤í¬ëœ ì–¸ì–´ ëª¨ë¸ë§ ê¸°ë²•"
      ],
      "metadata": {
        "id": "DQ4-IuXMG4gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ë§ˆìŠ¤í¬ëœ ì–¸ì–´ ëª¨ë¸ë§(MLM)ì´ë€?**\n",
        "    - **ì •ì˜** : ë¬¸ì¥ì—ì„œ ì¼ë¶€ ë‹¨ì–´ë¥¼ ìˆ¨ê¸°ê³  ì˜ˆì¸¡í•˜ëŠ” í•™ìŠµ ë°©ë²• â†’ ë¹ˆì¹¸ ì±„ìš°ê¸°ì™€ ìœ ì‚¬í•œ ê°œë…\n",
        "    - **ëª©ì ** : ì–‘ë°©í–¥ ë¬¸ë§¥ ì´í•´ ëŠ¥ë ¥ í–¥ìƒ â†’ ì•ë’¤ ë¬¸ë§¥ì„ ëª¨ë‘ ê³ ë ¤í•œ ì–¸ì–´ ì´í•´\n",
        "    - **ë°©ì‹** : [MASK] í† í°ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ê°€ë¦¬ê³  ì›ë˜ ë‹¨ì–´ ì˜ˆì¸¡ â†’ **ìê¸°ì§€ë„í•™ìŠµ(Self-supervised Learning)**\n",
        "\n",
        "- **ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?**\n",
        "    - **ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„** : ì–¸ì–´ ëª¨ë¸ì˜ ê¸°ì´ˆ í•™ìŠµ â†’ BERT ëª¨ë¸ì´ ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ì—ì„œ ì–¸ì–´ íŒ¨í„´ í•™ìŠµ\n",
        "    - **ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸** : í•™ìŠµëœ ëª¨ë¸ì˜ ì–¸ì–´ ì´í•´ë„ í‰ê°€ â†’ ë¬¸ë§¥ìƒ ì ì ˆí•œ ë‹¨ì–´ ì˜ˆì¸¡ ëŠ¥ë ¥ í™•ì¸\n",
        "    - **ì‹¤ì œ ì‘ìš© ì„œë¹„ìŠ¤** : ìë™ ì™„ì„±, ë§ì¶¤ë²• ê²€ì‚¬ ë“± â†’ ê²€ìƒ‰ì–´ ì¶”ì²œ, ë¬¸ì„œ ì‘ì„± ë³´ì¡°\n",
        "    - **êµìœ¡/ì—°êµ¬ ëª©ì ** : ì–¸ì–´ ëª¨ë¸ ì‘ë™ ì›ë¦¬ ì´í•´ â†’ AIì˜ ì–¸ì–´ ì²˜ë¦¬ ëŠ¥ë ¥ ì‹œì—°\n",
        "- **ë“±ì¥ ë°°ê²½**\n",
        "    - ê¸°ì¡´ ì–¸ì–´ ëª¨ë¸ë“¤ì˜ í•œê³„ì  ê·¹ë³µì´ ëª©ì \n",
        "    - ì „í†µì ì¸ ì–¸ì–´ ëª¨ë¸ì€ ë‹¨ë°©í–¥(ì™¼ìª½â†’ì˜¤ë¥¸ìª½)ìœ¼ë¡œë§Œ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡\n",
        "    - ì‹¤ì œ ì¸ê°„ì˜ ì–¸ì–´ ì´í•´ëŠ” ì•ë’¤ ë¬¸ë§¥ì„ ëª¨ë‘ ê³ ë ¤\n",
        "    - ì˜ˆì‹œ : BERTëŠ” ë¬¸ì¥ì—ì„œ ë¬´ì‘ìœ„ë¡œ 15%ì˜ ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì–‘ë°©í–¥ ë¬¸ë§¥ì„ í•™ìŠµ\n",
        "\n",
        "- **ë§ˆìŠ¤í‚¹ ë°©ì‹**\n",
        "|ë§ˆìŠ¤í‚¹ ë°©ì‹|ë¹„ìœ¨|ì²˜ë¦¬ ë°©ë²•|\n",
        "|---|---|---|\n",
        "|[MASK] í† í° êµì²´|80%|ì‹¤ì œ [MASK] í† í°ìœ¼ë¡œ ëŒ€ì²´ |\n",
        "|ëœë¤ ë‹¨ì–´ êµì²´|10%|ë‹¤ë¥¸ ë¬´ì‘ìœ„ ë‹¨ì–´ë¡œ|\n",
        "|êµì²´ì›ë³¸ ìœ ì§€|10%|ì›ë˜ ë‹¨ì–´ ê·¸ëŒ€ë¡œ ìœ ì§€|"
      ],
      "metadata": {
        "id": "Ygqh8zmVHCXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **í•™ìŠµ ê³¼ì •**\n",
        "    1. **ì…ë ¥ ë¬¸ì¥ ì¤€ë¹„**: \"The cat is sitting on the mat\"\n",
        "    2. **ë§ˆìŠ¤í‚¹ ì ìš©**: \"The [MASK] is sitting on the mat\"\n",
        "    3. **ë¬¸ë§¥ ë¶„ì„**: ì•ë’¤ ë‹¨ì–´ë“¤(\"The\", \"is\", \"sitting\", \"on\", \"the\", \"mat\") ê³ ë ¤\n",
        "    4. **ë‹¨ì–´ ì˜ˆì¸¡**: ê°€ëŠ¥í•œ ë‹¨ì–´ë“¤ì˜ í™•ë¥  ë¶„í¬ ê³„ì‚°\n",
        "    5. **ì •ë‹µê³¼ ë¹„êµ**: ì›ë˜ ë‹¨ì–´(\"cat\")ì™€ ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµí•˜ì—¬ í•™ìŠµ"
      ],
      "metadata": {
        "id": "02QAzIqdhCRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì˜ˆì œ 1: ë§ˆìŠ¤í¬ëœ ì–¸ì–´ ëª¨ë¸ë§ ì²´í—˜**"
      ],
      "metadata": {
        "id": "CgwwW0qeApzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# ë§ˆìŠ¤í¬ ì±„ìš°ê¸° íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
        "fill_mask = pipeline(\"fill-mask\", model=\"google-bert/bert-base-uncased\")\n",
        "\n",
        "# ì˜ˆì‹œ ë¬¸ì¥ë“¤\n",
        "sentences = [\n",
        "    \"The capital of France is [MASK].\",\n",
        "    \"I love to eat [MASK] for breakfast.\",\n",
        "    \"The [MASK] is shining brightly today.\"\n",
        "]\n",
        "\n",
        "print(\"=== ë§ˆìŠ¤í¬ëœ ì–¸ì–´ ëª¨ë¸ë§ ì²´í—˜ ===\")\n",
        "for sentence in sentences:\n",
        "    result = fill_mask(sentence)\n",
        "    print(f\"\\nì…ë ¥: {sentence}\")\n",
        "    print(\"ì˜ˆì¸¡ëœ ë‹¨ì–´ë“¤:\")\n",
        "    for i, prediction in enumerate(result[:3], 1):\n",
        "        print(f\"  {i}. {prediction['token_str']} (í™•ë¥ : {prediction['score']:.3f})\")"
      ],
      "metadata": {
        "id": "pdR-Qis0AqXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bd90ba-552d-4ed2-dcd9-4dd30667f5a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ë§ˆìŠ¤í¬ëœ ì–¸ì–´ ëª¨ë¸ë§ ì²´í—˜ ===\n",
            "\n",
            "ì…ë ¥: The capital of France is [MASK].\n",
            "ì˜ˆì¸¡ëœ ë‹¨ì–´ë“¤:\n",
            "  1. paris (í™•ë¥ : 0.417)\n",
            "  2. lille (í™•ë¥ : 0.071)\n",
            "  3. lyon (í™•ë¥ : 0.063)\n",
            "\n",
            "ì…ë ¥: I love to eat [MASK] for breakfast.\n",
            "ì˜ˆì¸¡ëœ ë‹¨ì–´ë“¤:\n",
            "  1. it (í™•ë¥ : 0.135)\n",
            "  2. them (í™•ë¥ : 0.086)\n",
            "  3. you (í™•ë¥ : 0.072)\n",
            "\n",
            "ì…ë ¥: The [MASK] is shining brightly today.\n",
            "ì˜ˆì¸¡ëœ ë‹¨ì–´ë“¤:\n",
            "  1. sun (í™•ë¥ : 0.740)\n",
            "  2. moon (í™•ë¥ : 0.029)\n",
            "  3. city (í™•ë¥ : 0.023)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì˜ˆì œ 2: ë¬¸ë§¥ì˜ ì¤‘ìš”ì„± ì´í•´**"
      ],
      "metadata": {
        "id": "f5JNjOlXkBNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë™ì¼í•œ ë‹¨ì–´ê°€ ë‹¤ë¥¸ ë¬¸ë§¥ì—ì„œ ì–´ë–»ê²Œ ì˜ˆì¸¡ë˜ëŠ”ì§€ ë¹„êµ\n",
        "context_examples = [\n",
        "    \"The [MASK] is flying in the sky.\",      # ìƒˆ, ë¹„í–‰ê¸° ë“±\n",
        "    \"The [MASK] is swimming in the ocean.\",  # ë¬¼ê³ ê¸°, ê³ ë˜ ë“±\n",
        "    \"The [MASK] is running in the park.\",    # ì‚¬ëŒ, ê°œ ë“±\n",
        "]\n",
        "\n",
        "print(\"\\n=== ë¬¸ë§¥ì— ë”°ë¥¸ ì˜ˆì¸¡ ë³€í™” ===\")\n",
        "for sentence in context_examples:\n",
        "    print(f\"\\në¬¸ì¥: {sentence}\")\n",
        "    results = fill_mask(sentence)\n",
        "    top_3 = [f\"'{r['token_str']}'\" for r in results[:3]]\n",
        "    print(f\"ìƒìœ„ 3ê°œ ì˜ˆì¸¡: {', '.join(top_3)}\")"
      ],
      "metadata": {
        "id": "gFjB_3-LkD-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ec11ec-303a-41c2-bd7e-d08d82863c20"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ë¬¸ë§¥ì— ë”°ë¥¸ ì˜ˆì¸¡ ë³€í™” ===\n",
            "\n",
            "ë¬¸ì¥: The [MASK] is flying in the sky.\n",
            "ìƒìœ„ 3ê°œ ì˜ˆì¸¡: 'sun', 'moon', 'plane'\n",
            "\n",
            "ë¬¸ì¥: The [MASK] is swimming in the ocean.\n",
            "ìƒìœ„ 3ê°œ ì˜ˆì¸¡: 'girl', 'boy', 'man'\n",
            "\n",
            "ë¬¸ì¥: The [MASK] is running in the park.\n",
            "ìƒìœ„ 3ê°œ ì˜ˆì¸¡: 'train', 'horse', 'track'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì˜ˆì œ 3: ì‹¤ì‹œê°„ MLM ì²´í—˜ ë„êµ¬**"
      ],
      "metadata": {
        "id": "w2lJYkaGkEPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_mlm():\n",
        "    \"\"\"ì‚¬ìš©ìê°€ ì§ì ‘ ë¬¸ì¥ì„ ì…ë ¥í•˜ì—¬ MLMì„ ì²´í—˜í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜\"\"\"\n",
        "    fill_mask = pipeline(\"fill-mask\", model=\"google-bert/bert-base-uncased\")\n",
        "\n",
        "    print(\"=== ëŒ€í™”í˜• ë§ˆìŠ¤í¬ëœ ì–¸ì–´ ëª¨ë¸ë§ ===\")\n",
        "    print(\"ë¬¸ì¥ì— [MASK]ë¥¼ í¬í•¨í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\në¬¸ì¥ ì…ë ¥: \")\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "            break\n",
        "\n",
        "        if '[MASK]' not in user_input:\n",
        "            print(\"ë¬¸ì¥ì— [MASK]ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”!\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            results = fill_mask(user_input)\n",
        "            print(f\"\\nì…ë ¥: {user_input}\")\n",
        "            print(\"ì˜ˆì¸¡ ê²°ê³¼:\")\n",
        "\n",
        "            for i, result in enumerate(results[:5], 1):\n",
        "                word = result['token_str']\n",
        "                score = result['score']\n",
        "                completed_sentence = user_input.replace('[MASK]', word)\n",
        "                print(f\"{i}. {completed_sentence} (ì‹ ë¢°ë„: {score:.3f})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
        "\n",
        "# í•¨ìˆ˜ ì‹¤í–‰ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)\n",
        "interactive_mlm()"
      ],
      "metadata": {
        "id": "Depn5JQ9kEY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf8e56a-e4dc-4903-9b25-31153a9c4e91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ëŒ€í™”í˜• ë§ˆìŠ¤í¬ëœ ì–¸ì–´ ëª¨ë¸ë§ ===\n",
            "ë¬¸ì¥ì— [MASK]ë¥¼ í¬í•¨í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
            "\n",
            "ë¬¸ì¥ ì…ë ¥: I'm wearing [MASK].\n",
            "\n",
            "ì…ë ¥: I'm wearing [MASK].\n",
            "ì˜ˆì¸¡ ê²°ê³¼:\n",
            "1. I'm wearing jeans. (ì‹ ë¢°ë„: 0.135)\n",
            "2. I'm wearing it. (ì‹ ë¢°ë„: 0.127)\n",
            "3. I'm wearing this. (ì‹ ë¢°ë„: 0.078)\n",
            "4. I'm wearing nothing. (ì‹ ë¢°ë„: 0.057)\n",
            "5. I'm wearing heels. (ì‹ ë¢°ë„: 0.045)\n",
            "\n",
            "ë¬¸ì¥ ì…ë ¥: I'm wearing a [MASK].\n",
            "\n",
            "ì…ë ¥: I'm wearing a [MASK].\n",
            "ì˜ˆì¸¡ ê²°ê³¼:\n",
            "1. I'm wearing a dress. (ì‹ ë¢°ë„: 0.361)\n",
            "2. I'm wearing a bra. (ì‹ ë¢°ë„: 0.090)\n",
            "3. I'm wearing a robe. (ì‹ ë¢°ë„: 0.083)\n",
            "4. I'm wearing a suit. (ì‹ ë¢°ë„: 0.064)\n",
            "5. I'm wearing a shirt. (ì‹ ë¢°ë„: 0.029)\n",
            "\n",
            "ë¬¸ì¥ ì…ë ¥: quit\n",
            "í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0g36MizoMox8"
      }
    }
  ]
}