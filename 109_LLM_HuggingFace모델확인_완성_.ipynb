{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmVO_XULPo7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyBc3Lm3PrXK",
        "outputId": "ec7383e4-8493-4e87-d0e9-bdf8b2bc7438"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hugging Face 모델 확인하기**"
      ],
      "metadata": {
        "id": "xAPO58qbDYi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAmo5uhXQ46c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 💡 **NOTE**\n",
        "    - 이 노트북의 코드를 실행하려면 GPU를 사용하는 것이 좋습니다. 구글 코랩에서는 **런타임 > 런타임 유형 변경 > 하드웨어 가속기 > T4 GPU**를 선택하세요."
      ],
      "metadata": {
        "id": "KHIcfXn8RArA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "K-OX9xcYMp_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.Hugging Face 사용**"
      ],
      "metadata": {
        "id": "QD5DBVW269sN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Hugging Face**\n",
        "    - Hugging Face는 AI 모델과 데이터셋을 공유·활용할 수 있는 대표적인 오픈소스 플랫폼, 커뮤니티\n",
        "        - **모델 허브(Model Hub)** : 수만 개의 공개된 머신러닝/딥러닝 모델을 누구나 다운로드·활용 가능\n",
        "        - **데이터셋 허브(Datasets)** : 다양한 표준/비표준 데이터셋을 간편하게 불러와 실험 가능\n",
        "        - **Transformers 라이브러리** : BERT, GPT, T5, LLaMA 등 최신 NLP·멀티모달 모델을 손쉽게 사용 가능\n",
        "        - **PEFT/Accelerate 등 도구** : 파인튜닝·분산 학습·최적화 지원\n",
        "        - **커뮤니티**: 연구자·개발자가 모델과 코드를 공유하고 협업할 수 있는 생태계\n",
        "\n",
        "- **transformers**\n",
        "    - transformers library https://huggingface.co/docs/transformers/index\n",
        "    - Hugging Face에서 제공하는 사전 훈련된 AI 모델들을 쉽게 사용할 수 있게 해주는 파이썬 라이브러리\n",
        "    - 복잡한 AI 모델을 간단한 코드로 사용할 수 있게 해주는 도구\n",
        "\n",
        "- **pipeline**\n",
        "    - https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
        "    - pipeline은 자연어 처리(NLP)·비전·오디오 등 다양한 AI 태스크를 쉽게 실행할 수 있도록 미리 구성된 추론(실행) 도구\n",
        "    - 태스크 이름(예: \"sentiment-analysis\", \"translation\")을 입력하면,자동으로 적합한 모델 + 토크나이저 + 전/후처리 로직을 불러와,사용자가 텍스트/이미지/오디오를 바로 넣어 결과를 얻을 수 있게 함\n",
        "\n",
        "    - **pipeline(sentiment-analysis)**\n",
        "        - Hugging Face Pipelines Documentation :  \n",
        "        - 텍스트의 감정(긍정/부정) 분석에 특화된 즉시 사용 가능한 AI 모델을 사용하는 파이프라인의 작업(task) 이름\n",
        "        - 감정 분석에 특화된 즉시 사용 가능한 AI 모델을 사용하는 작업(task) 이름\n",
        "        - (AI모델 X) 내부적으로 BERT, RoBERTa, DistilBERT 등의 실제 신경망 모델이 동작\n"
      ],
      "metadata": {
        "id": "olZXCZdcWh_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **예제 1: 모델 정보 확인하기**"
      ],
      "metadata": {
        "id": "jNIZzwy-Af3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import model_info\n",
        "\n",
        "# 예: BERT base uncased 모델 정보 불러오기\n",
        "# info = model_info(\"bert-base-uncased\")\n",
        "info = model_info(\"google-bert/bert-base-uncased\")\n",
        "# info = model_info(\"Qwen/Qwen3-Omni-30B-A3B-Instruct\")\n",
        "\n",
        "# 전체 메타데이터 보기\n",
        "print(info.cardData)\n",
        "\n",
        "# 특정 항목 추출 (있을 경우만)\n",
        "if \"model_size\" in info.cardData:\n",
        "    print(\"모델 파라미터 수:\", info.cardData[\"model_size\"])\n",
        "if \"datasets\" in info.cardData:\n",
        "    print(\"학습 데이터셋:\", info.cardData[\"datasets\"])\n"
      ],
      "metadata": {
        "id": "lg8uzS0R8qJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b0addf-4a87-4639-8cd7-3ba6b2fe33e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets:\n",
            "- bookcorpus\n",
            "- wikipedia\n",
            "language: en\n",
            "license: apache-2.0\n",
            "tags:\n",
            "- exbert\n",
            "학습 데이터셋: ['bookcorpus', 'wikipedia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info.author"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ssjyX-5RQPUV",
        "outputId": "10d9501a-8a24-4a8b-a15f-174e5d579ecd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'google-bert'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer, BertConfig\n",
        "import torch\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "model_name = \"google-bert/bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "\n",
        "# 모델 구성 정보 출력\n",
        "print(\"=== BERT Base Uncased 모델 정보 ===\")\n",
        "print(f\"모델 이름: {model_name}\")\n",
        "print(f\"어휘 사전 크기: {config.vocab_size}\")\n",
        "print(f\"히든 레이어 수: {config.num_hidden_layers}\")\n",
        "print(f\"히든 사이즈: {config.hidden_size}\")\n",
        "print(f\"어텐션 헤드 수: {config.num_attention_heads}\")\n",
        "print(f\"최대 시퀀스 길이: {config.max_position_embeddings}\")\n",
        "\n",
        "# 파라미터 수 계산\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"총 파라미터 수: {total_params:,} ({total_params/1e6:.1f}M)\")"
      ],
      "metadata": {
        "id": "AiXxzDp3AVdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "78b3fbd991ed44d8b53d94a50faa1d15",
            "aac6715b9af6401babaef661ef729210",
            "dee74345fe9345d3864861760815ba4a",
            "a8a5a90c3c894f87a6accc236413509c",
            "47cc1d6940094cdb97d5d26542e9700c",
            "1f40d36bf2604d219abe7075d6616032",
            "24157fd011c64dbaa3a6c84964bea532",
            "ac485663fe86466a91d2e8a806b0e541",
            "16bcecf727c7439fb18c5d258561f2f0",
            "41c34e87e3f2418e89ab240f1db9b756",
            "88aaf11ac4344d4fad858bce6308ccdf",
            "7a1765ca6c1c41dfafd64c98e0c3f4df",
            "92f0c87c0d8947eaab93db02bcbac93b",
            "69f519caaae34fb5b1c4f1e6a868fb45",
            "3238c2bb9197496eba8773869892bee1",
            "5143b7fe23124d92a3207ffac09e7f02",
            "702c3725fd9c47b78a56899bda35a7b9",
            "93005980ef9d43b6a64d1ef04510d02c",
            "033878ecd49f4bff89f9d0b3a50e850a",
            "d205e07a241f4c86b0cbf5c470d53886",
            "db724a2e9d93441dbb5d46a449896e13",
            "4b83782abb564b44a5b411ccf968d007",
            "35a53a085400420e8766516dff32464a",
            "ce9543c8f8194ad7ae3d3b4fa01de03f",
            "e8aa4b41cfb54c4ea64e10bdeca67dff",
            "5c04a61077a044fa8398288ce01cfd58",
            "59e4a77952d34c21ad6bcc743c2323a4",
            "6371e3f1758f400da290fc8e736eaa9d",
            "a30c4830accb4699a73ac2f5ddcfb458",
            "bf0bd9e29a1e4694807c2dab6ad979fa",
            "c00b2b5934a346cab806f0e919de8964",
            "0163a6d106cf4af381cba38c42d74c0d",
            "4ecae741dfd14a918fab068d975cf2b9",
            "8df061aa349d4bb2b7cc4b1d9e66f4e7",
            "a962bc3400154029bfffc3ef803310f8",
            "3bf11ab44f57485988d53386f0f56fff",
            "8bbaeee2cd9b43b5a449985231066fe1",
            "739a7a4e94dc464fb7e26c63be062abc",
            "24d9ef30b01c4b958ea3052b8fbc164a",
            "fa561740fee74bb391eb984c73881268",
            "4820af5fa5b64a74b5aabe7e6b6b7b0a",
            "cd9259d980d14049a42311e46b9f3b72",
            "5b84b74fa0674564a0b98eadf2345f85",
            "354894b3e0e14514a4ba581d1a45d44e",
            "6f6f68528ade45dfb78def142039d9b0",
            "dce46cf8c77240b4914c3fc9a9bb768c",
            "7310204367d54ed1afaed5738de0b7a9",
            "e3a1352d4d76428ebb9da2d0f844b720",
            "740e436c0e824266b2a5c856ee50061d",
            "6623fabfac8740358d607102345b875b",
            "1f52124db0d84e0e8c11ecf503267807",
            "9229577ff2da4a5cb66a04ae18be5d08",
            "736bbb7d878840468267d9ea318cf479",
            "02044ad4842f495c90f50fd4145c31f7",
            "f92c767112104818b0095abfc3518deb"
          ]
        },
        "outputId": "e5e35905-08a9-4f08-b6d8-6c08781911e6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78b3fbd991ed44d8b53d94a50faa1d15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a1765ca6c1c41dfafd64c98e0c3f4df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35a53a085400420e8766516dff32464a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8df061aa349d4bb2b7cc4b1d9e66f4e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f6f68528ade45dfb78def142039d9b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BERT Base Uncased 모델 정보 ===\n",
            "모델 이름: google-bert/bert-base-uncased\n",
            "어휘 사전 크기: 30522\n",
            "히든 레이어 수: 12\n",
            "히든 사이즈: 768\n",
            "어텐션 헤드 수: 12\n",
            "최대 시퀀스 길이: 512\n",
            "총 파라미터 수: 109,482,240 (109.5M)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **예제 2: 모델 사용해보기**"
      ],
      "metadata": {
        "id": "EQnXm72-ApDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시 텍스트로 모델 테스트\n",
        "text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# 모델 추론\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# 결과 분석\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(f\"입력 텍스트: {text}\")\n",
        "print(f\"토큰화된 입력: {tokenizer.tokenize(text)}\")\n",
        "print(f\"출력 텐서 크기: {last_hidden_states.shape}\")\n",
        "print(f\"각 토큰의 임베딩 차원: {last_hidden_states.shape[-1]}\")"
      ],
      "metadata": {
        "id": "TDExX_RNApi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d45551-65e6-42ba-d0e9-f18459bad835"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텍스트: The quick brown fox jumps over the lazy dog.\n",
            "토큰화된 입력: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "출력 텐서 크기: torch.Size([1, 12, 768])\n",
            "각 토큰의 임베딩 차원: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Masked Language Modeling(MLM)소개**\n",
        "마스크된 언어 모델링 기법"
      ],
      "metadata": {
        "id": "DQ4-IuXMG4gS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **마스크된 언어 모델링(MLM)이란?**\n",
        "    - **정의** : 문장에서 일부 단어를 숨기고 예측하는 학습 방법 → 빈칸 채우기와 유사한 개념\n",
        "    - **목적** : 양방향 문맥 이해 능력 향상 → 앞뒤 문맥을 모두 고려한 언어 이해\n",
        "    - **방식** : [MASK] 토큰으로 단어를 가리고 원래 단어 예측 → **자기지도학습(Self-supervised Learning)**\n",
        "\n",
        "- **언제 사용하는가?**\n",
        "    - **사전 훈련 단계** : 언어 모델의 기초 학습 → BERT 모델이 대량의 텍스트에서 언어 패턴 학습\n",
        "    - **모델 성능 테스트** : 학습된 모델의 언어 이해도 평가 → 문맥상 적절한 단어 예측 능력 확인\n",
        "    - **실제 응용 서비스** : 자동 완성, 맞춤법 검사 등 → 검색어 추천, 문서 작성 보조\n",
        "    - **교육/연구 목적** : 언어 모델 작동 원리 이해 → AI의 언어 처리 능력 시연\n",
        "- **등장 배경**\n",
        "    - 기존 언어 모델들의 한계점 극복이 목적\n",
        "    - 전통적인 언어 모델은 단방향(왼쪽→오른쪽)으로만 단어를 예측\n",
        "    - 실제 인간의 언어 이해는 앞뒤 문맥을 모두 고려\n",
        "    - 예시 : BERT는 문장에서 무작위로 15%의 단어를 마스킹하여 양방향 문맥을 학습\n",
        "\n",
        "- **마스킹 방식**\n",
        "|마스킹 방식|비율|처리 방법|\n",
        "|---|---|---|\n",
        "|[MASK] 토큰 교체|80%|실제 [MASK] 토큰으로 대체 |\n",
        "|랜덤 단어 교체|10%|다른 무작위 단어로|\n",
        "|교체원본 유지|10%|원래 단어 그대로 유지|"
      ],
      "metadata": {
        "id": "Ygqh8zmVHCXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **학습 과정**\n",
        "    1. **입력 문장 준비**: \"The cat is sitting on the mat\"\n",
        "    2. **마스킹 적용**: \"The [MASK] is sitting on the mat\"\n",
        "    3. **문맥 분석**: 앞뒤 단어들(\"The\", \"is\", \"sitting\", \"on\", \"the\", \"mat\") 고려\n",
        "    4. **단어 예측**: 가능한 단어들의 확률 분포 계산\n",
        "    5. **정답과 비교**: 원래 단어(\"cat\")와 예측 결과 비교하여 학습"
      ],
      "metadata": {
        "id": "02QAzIqdhCRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **예제 1: 마스크된 언어 모델링 체험**"
      ],
      "metadata": {
        "id": "CgwwW0qeApzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 마스크 채우기 파이프라인 생성\n",
        "fill_mask = pipeline(\"fill-mask\", model=\"google-bert/bert-base-uncased\")\n",
        "\n",
        "# 예시 문장들\n",
        "sentences = [\n",
        "    \"The capital of France is [MASK].\",\n",
        "    \"I love to eat [MASK] for breakfast.\",\n",
        "    \"The [MASK] is shining brightly today.\"\n",
        "]\n",
        "\n",
        "print(\"=== 마스크된 언어 모델링 체험 ===\")\n",
        "for sentence in sentences:\n",
        "    result = fill_mask(sentence)\n",
        "    print(f\"\\n입력: {sentence}\")\n",
        "    print(\"예측된 단어들:\")\n",
        "    for i, prediction in enumerate(result[:3], 1):\n",
        "        print(f\"  {i}. {prediction['token_str']} (확률: {prediction['score']:.3f})\")"
      ],
      "metadata": {
        "id": "pdR-Qis0AqXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bd90ba-552d-4ed2-dcd9-4dd30667f5a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 마스크된 언어 모델링 체험 ===\n",
            "\n",
            "입력: The capital of France is [MASK].\n",
            "예측된 단어들:\n",
            "  1. paris (확률: 0.417)\n",
            "  2. lille (확률: 0.071)\n",
            "  3. lyon (확률: 0.063)\n",
            "\n",
            "입력: I love to eat [MASK] for breakfast.\n",
            "예측된 단어들:\n",
            "  1. it (확률: 0.135)\n",
            "  2. them (확률: 0.086)\n",
            "  3. you (확률: 0.072)\n",
            "\n",
            "입력: The [MASK] is shining brightly today.\n",
            "예측된 단어들:\n",
            "  1. sun (확률: 0.740)\n",
            "  2. moon (확률: 0.029)\n",
            "  3. city (확률: 0.023)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **예제 2: 문맥의 중요성 이해**"
      ],
      "metadata": {
        "id": "f5JNjOlXkBNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 동일한 단어가 다른 문맥에서 어떻게 예측되는지 비교\n",
        "context_examples = [\n",
        "    \"The [MASK] is flying in the sky.\",      # 새, 비행기 등\n",
        "    \"The [MASK] is swimming in the ocean.\",  # 물고기, 고래 등\n",
        "    \"The [MASK] is running in the park.\",    # 사람, 개 등\n",
        "]\n",
        "\n",
        "print(\"\\n=== 문맥에 따른 예측 변화 ===\")\n",
        "for sentence in context_examples:\n",
        "    print(f\"\\n문장: {sentence}\")\n",
        "    results = fill_mask(sentence)\n",
        "    top_3 = [f\"'{r['token_str']}'\" for r in results[:3]]\n",
        "    print(f\"상위 3개 예측: {', '.join(top_3)}\")"
      ],
      "metadata": {
        "id": "gFjB_3-LkD-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ec11ec-303a-41c2-bd7e-d08d82863c20"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 문맥에 따른 예측 변화 ===\n",
            "\n",
            "문장: The [MASK] is flying in the sky.\n",
            "상위 3개 예측: 'sun', 'moon', 'plane'\n",
            "\n",
            "문장: The [MASK] is swimming in the ocean.\n",
            "상위 3개 예측: 'girl', 'boy', 'man'\n",
            "\n",
            "문장: The [MASK] is running in the park.\n",
            "상위 3개 예측: 'train', 'horse', 'track'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **예제 3: 실시간 MLM 체험 도구**"
      ],
      "metadata": {
        "id": "w2lJYkaGkEPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_mlm():\n",
        "    \"\"\"사용자가 직접 문장을 입력하여 MLM을 체험할 수 있는 함수\"\"\"\n",
        "    fill_mask = pipeline(\"fill-mask\", model=\"google-bert/bert-base-uncased\")\n",
        "\n",
        "    print(\"=== 대화형 마스크된 언어 모델링 ===\")\n",
        "    print(\"문장에 [MASK]를 포함하여 입력하세요. 종료하려면 'quit'를 입력하세요.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\n문장 입력: \")\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"프로그램을 종료합니다.\")\n",
        "            break\n",
        "\n",
        "        if '[MASK]' not in user_input:\n",
        "            print(\"문장에 [MASK]를 포함해주세요!\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            results = fill_mask(user_input)\n",
        "            print(f\"\\n입력: {user_input}\")\n",
        "            print(\"예측 결과:\")\n",
        "\n",
        "            for i, result in enumerate(results[:5], 1):\n",
        "                word = result['token_str']\n",
        "                score = result['score']\n",
        "                completed_sentence = user_input.replace('[MASK]', word)\n",
        "                print(f\"{i}. {completed_sentence} (신뢰도: {score:.3f})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류가 발생했습니다: {e}\")\n",
        "\n",
        "# 함수 실행 (주석 해제하여 사용)\n",
        "interactive_mlm()"
      ],
      "metadata": {
        "id": "Depn5JQ9kEY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf8e56a-e4dc-4903-9b25-31153a9c4e91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 대화형 마스크된 언어 모델링 ===\n",
            "문장에 [MASK]를 포함하여 입력하세요. 종료하려면 'quit'를 입력하세요.\n",
            "\n",
            "문장 입력: I'm wearing [MASK].\n",
            "\n",
            "입력: I'm wearing [MASK].\n",
            "예측 결과:\n",
            "1. I'm wearing jeans. (신뢰도: 0.135)\n",
            "2. I'm wearing it. (신뢰도: 0.127)\n",
            "3. I'm wearing this. (신뢰도: 0.078)\n",
            "4. I'm wearing nothing. (신뢰도: 0.057)\n",
            "5. I'm wearing heels. (신뢰도: 0.045)\n",
            "\n",
            "문장 입력: I'm wearing a [MASK].\n",
            "\n",
            "입력: I'm wearing a [MASK].\n",
            "예측 결과:\n",
            "1. I'm wearing a dress. (신뢰도: 0.361)\n",
            "2. I'm wearing a bra. (신뢰도: 0.090)\n",
            "3. I'm wearing a robe. (신뢰도: 0.083)\n",
            "4. I'm wearing a suit. (신뢰도: 0.064)\n",
            "5. I'm wearing a shirt. (신뢰도: 0.029)\n",
            "\n",
            "문장 입력: quit\n",
            "프로그램을 종료합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0g36MizoMox8"
      }
    }
  ]
}